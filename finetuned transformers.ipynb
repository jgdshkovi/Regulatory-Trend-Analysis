{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56a9ab9-7c7d-41c3-a35b-f630d0356af1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4746136c-54b3-4c18-8494-cf877f411704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/wes/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/wes/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/wes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65433b89-0957-433e-843b-f95bc063d9e7",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781fa0a9-d7a6-4d2a-b0f4-606bf5b22fe4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78cd3af-15a3-4c84-a12e-fef88f814229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_summary</th>\n",
       "      <th>article_url</th>\n",
       "      <th>date_published</th>\n",
       "      <th>title_summary</th>\n",
       "      <th>cleaned_title_summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Attorney General Merrick B. Garland Statement ...</td>\n",
       "      <td>This afternoon, a Deputy U.S. Marshal and two ...</td>\n",
       "      <td>https://www.justice.gov//opa/pr/attorney-gener...</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>Attorney General Merrick B. Garland Statement ...</td>\n",
       "      <td>attorney general merrick b garland statement s...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Justice Department Recovers Fraudulent Transfe...</td>\n",
       "      <td>The Justice Department announced today that it...</td>\n",
       "      <td>https://www.justice.gov//opa/pr/justice-depart...</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>Justice Department Recovers Fraudulent Transfe...</td>\n",
       "      <td>justice department recovers fraudulent transfe...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Justice Department Secures Agreement to Resolv...</td>\n",
       "      <td>The Justice Department announced today that Ir...</td>\n",
       "      <td>https://www.justice.gov//opa/pr/justice-depart...</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>Justice Department Secures Agreement to Resolv...</td>\n",
       "      <td>justice department secures agreement resolve s...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       article_title  \\\n",
       "0  Attorney General Merrick B. Garland Statement ...   \n",
       "1  Justice Department Recovers Fraudulent Transfe...   \n",
       "2  Justice Department Secures Agreement to Resolv...   \n",
       "\n",
       "                                     article_summary  \\\n",
       "0  This afternoon, a Deputy U.S. Marshal and two ...   \n",
       "1  The Justice Department announced today that it...   \n",
       "2  The Justice Department announced today that Ir...   \n",
       "\n",
       "                                         article_url date_published  \\\n",
       "0  https://www.justice.gov//opa/pr/attorney-gener...     2024-04-29   \n",
       "1  https://www.justice.gov//opa/pr/justice-depart...     2024-04-29   \n",
       "2  https://www.justice.gov//opa/pr/justice-depart...     2024-04-29   \n",
       "\n",
       "                                       title_summary  \\\n",
       "0  Attorney General Merrick B. Garland Statement ...   \n",
       "1  Justice Department Recovers Fraudulent Transfe...   \n",
       "2  Justice Department Secures Agreement to Resolv...   \n",
       "\n",
       "                               cleaned_title_summary  label  \n",
       "0  attorney general merrick b garland statement s...  False  \n",
       "1  justice department recovers fraudulent transfe...   True  \n",
       "2  justice department secures agreement resolve s...  False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/doj_data.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0326aa39-21b9-4081-abac-7578e94e8166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_summary</th>\n",
       "      <th>article_url</th>\n",
       "      <th>date_published</th>\n",
       "      <th>title_summary</th>\n",
       "      <th>cleaned_title_summary</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Attorney General Merrick B. Garland Statement ...</td>\n",
       "      <td>This afternoon, a Deputy U.S. Marshal and two ...</td>\n",
       "      <td>https://www.justice.gov//opa/pr/attorney-gener...</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>Attorney General Merrick B. Garland Statement ...</td>\n",
       "      <td>attorney general merrick b garland statement s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Justice Department Recovers Fraudulent Transfe...</td>\n",
       "      <td>The Justice Department announced today that it...</td>\n",
       "      <td>https://www.justice.gov//opa/pr/justice-depart...</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>Justice Department Recovers Fraudulent Transfe...</td>\n",
       "      <td>justice department recovers fraudulent transfe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Justice Department Secures Agreement to Resolv...</td>\n",
       "      <td>The Justice Department announced today that Ir...</td>\n",
       "      <td>https://www.justice.gov//opa/pr/justice-depart...</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>Justice Department Secures Agreement to Resolv...</td>\n",
       "      <td>justice department secures agreement resolve s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       article_title  \\\n",
       "0  Attorney General Merrick B. Garland Statement ...   \n",
       "1  Justice Department Recovers Fraudulent Transfe...   \n",
       "2  Justice Department Secures Agreement to Resolv...   \n",
       "\n",
       "                                     article_summary  \\\n",
       "0  This afternoon, a Deputy U.S. Marshal and two ...   \n",
       "1  The Justice Department announced today that it...   \n",
       "2  The Justice Department announced today that Ir...   \n",
       "\n",
       "                                         article_url date_published  \\\n",
       "0  https://www.justice.gov//opa/pr/attorney-gener...     2024-04-29   \n",
       "1  https://www.justice.gov//opa/pr/justice-depart...     2024-04-29   \n",
       "2  https://www.justice.gov//opa/pr/justice-depart...     2024-04-29   \n",
       "\n",
       "                                       title_summary  \\\n",
       "0  Attorney General Merrick B. Garland Statement ...   \n",
       "1  Justice Department Recovers Fraudulent Transfe...   \n",
       "2  Justice Department Secures Agreement to Resolv...   \n",
       "\n",
       "                               cleaned_title_summary  label  \n",
       "0  attorney general merrick b garland statement s...      0  \n",
       "1  justice department recovers fraudulent transfe...      1  \n",
       "2  justice department secures agreement resolve s...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_labels = lambda x: 1 if x == True else 0\n",
    "\n",
    "data['label'] = data['label'].apply(change_labels)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e1339f-9607-4c47-8f7b-2a231f40c401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe records: 6052\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataframe records: {len(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56147212-0f81-4f41-8af7-b6c7edcd7759",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61dd34ac-60bd-412b-95bc-ea84fdddeabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(data['cleaned_title_summary'].tolist(),\n",
    "                                                                      data['label'].tolist(),\n",
    "                                                                      test_size=0.2,\n",
    "                                                                      stratify=data['label'].tolist(),\n",
    "                                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7410b7df-66ff-4951-bad3-1c29fd6470f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Create DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46e02569-852d-4e6d-8309-c2e097619ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast all items in list to string\n",
    "train_texts = [str(element) for element in train_texts]\n",
    "test_texts = [str(element) for element in test_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51efff98-9b9f-4d88-9d03-aa50339c442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training and evaluation dataframes\n",
    "train_df = pd.DataFrame({\n",
    "    'label' : train_labels,\n",
    "    'text' : train_texts\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'label' : test_labels,\n",
    "    'text' : test_texts\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eef2f9c9-1fa1-4a66-a753-3f90f625aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset(s) from dataframe(s)\n",
    "train_data = Dataset.from_dict(train_df)\n",
    "test_data = Dataset.from_dict(test_df)\n",
    "\n",
    "# Create datasets dictionary\n",
    "dataset_dict = datasets.DatasetDict({'train': train_data, \n",
    "                                     'test': test_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5cbfebb-5dde-4758-86bf-6bfe80413cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 4841\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1211\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display dataset dictionary details\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429b19e-6fbe-4414-8720-c43402fac15b",
   "metadata": {},
   "source": [
    "### Finetune pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9cb261-2868-4412-90b4-15d28ef19189",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86b75a2c-2cec-4dd6-b034-773efdabed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96cc74f3-a735-4323-bdc7-b5f97e179696",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2666d420-2fff-486e-893e-6ce0d1957609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62a51f81-ee52-4c5c-8804-a25712156e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: 'FALSE', 1: 'TRUE'}\n",
    "label2id = {'FALSE': 0, 'TRUE': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "656d251e-965b-4324-bb44-cba040897649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3754b2d2-917a-4528-b2e7-4c3209c044db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8936fb03-ef47-460f-b005-3c557c9d4c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wes/miniforge3/envs/fads/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9a16dcb-d68a-4efb-8827-ed635623d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bb5ae6c-546d-407a-8702-e64ffb1ed145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b61c3cf94040d595d75781656fe477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4841 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846138c2300b4d3da36690a809b2d720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1211 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "tokenized_datasets = dataset_dict.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b845725e-7f92-491c-b1c8-2fdb6afe41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training and eval datasets\n",
    "train_dataset = tokenized_datasets['train'].shuffle(seed=42)\n",
    "eval_dataset = tokenized_datasets['test'].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ac68806-b282-46bc-9321-51cffd1cc409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate bert model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', \n",
    "                                                           num_labels=2,\n",
    "                                                           id2label=id2label, \n",
    "                                                           label2id=label2id\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00d8309b-236a-45cf-9e2e-fc568fa7415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='finetuned_bert_model',\n",
    "    num_train_epochs=2,\n",
    "    \n",
    "    # learning_rate=2e-5,\n",
    "    # per_device_train_batch_size=16,\n",
    "    # per_device_eval_batch_size=16,\n",
    "\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=0.1,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d2d5a0e-1a71-42d1-ae80-43aecbf6ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training and eval datasets\n",
    "train_dataset = tokenized_datasets['train'].shuffle(seed=42)\n",
    "eval_dataset = tokenized_datasets['test'].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cb4cf65-36a8-4694-a882-a7ec1819b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41001fd4-62a0-470f-927a-43ed9b174bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1212' max='1212' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1212/1212 24:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.069025</td>\n",
       "      <td>0.985962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.064670</td>\n",
       "      <td>0.985962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1212, training_loss=0.1413930638788557, metrics={'train_runtime': 1466.5862, 'train_samples_per_second': 6.602, 'train_steps_per_second': 0.826, 'total_flos': 2547441237995520.0, 'train_loss': 0.1413930638788557, 'epoch': 2.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab6a99-6208-474c-94b6-5d10ca910fc8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "845a02f5-dc34-4e2d-9a3d-e368407c243d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wes/miniforge3/envs/fads/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a9fcda6-74d7-4ba4-838f-da585b6faf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65ba0783-39b7-4c90-8e3f-1054e995b769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26ee51785ee46be8cef4828d42b20f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4841 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eddfaf8966844bfae95b6b90b8a4149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1211 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "tokenized_datasets = dataset_dict.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "330f5514-0352-4adc-a9ee-3d6d0cb86492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training and eval datasets\n",
    "train_dataset = tokenized_datasets['train'].shuffle(seed=42)\n",
    "eval_dataset = tokenized_datasets['test'].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20343e8c-80d0-4432-82d9-a8f574a2dd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate distilbert model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert/distilbert-base-uncased', \n",
    "                                                           num_labels=2, \n",
    "                                                           id2label=id2label, \n",
    "                                                           label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48c3687d-ad1d-432f-8a88-17a45ac1ab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='finetuned_distilbert_model',\n",
    "    num_train_epochs=2,\n",
    "    \n",
    "    # learning_rate=2e-5,\n",
    "    # per_device_train_batch_size=16,\n",
    "    # per_device_eval_batch_size=16,\n",
    "    \n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=0.1,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afb91fd0-fbb6-4c3e-be42-48ee39874ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training and eval datasets\n",
    "train_dataset = tokenized_datasets['train'].shuffle(seed=42)\n",
    "eval_dataset = tokenized_datasets['test'].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd2aeaf3-1b33-4758-b9e0-c189c6721ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d5644a6-dccf-486f-b79e-c12dffa38731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1212' max='1212' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1212/1212 13:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>0.064406</td>\n",
       "      <td>0.988439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.064900</td>\n",
       "      <td>0.041690</td>\n",
       "      <td>0.992568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1212, training_loss=0.12198464154410284, metrics={'train_runtime': 827.71, 'train_samples_per_second': 11.697, 'train_steps_per_second': 1.464, 'total_flos': 1282549353787392.0, 'train_loss': 0.12198464154410284, 'epoch': 2.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e88ac7c-4f85-4ae1-94ce-70c373eb5de8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98971ff3-766b-44f7-8897-dfc1d0c29bdd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c15ec38c-1be5-42d1-bc26-e53c5c59b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(doc):\n",
    "    \n",
    "    # normalize Text\n",
    "    doc = doc.lower()\n",
    "\n",
    "    # remove unnecessary whitespaces\n",
    "    doc = re.sub('\\s+', ' ', doc)\n",
    "    doc = doc.strip()\n",
    "    \n",
    "    # remove html tags\n",
    "    doc = re.sub('<.*?>', '', doc)\n",
    "    \n",
    "    # remove email addresses\n",
    "    doc = re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)', '', doc)\n",
    "    \n",
    "    # remove url\n",
    "    doc = re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '', doc)\n",
    "    \n",
    "    # remove accented characters\n",
    "    doc = unicodedata.normalize('NFKD', doc).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "    # remove special symbols/punctuation\n",
    "    doc = re.sub(r'[^\\w ]+', '', doc)\n",
    "\n",
    "    # remove stopwords\n",
    "    doc = ' '.join([word for word in doc.split() if word not in english_stopwords])\n",
    "\n",
    "    # lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    doc = ' '.join([lemmatizer.lemmatize(word) for word in word_tokenize(doc)])\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83698b7-149f-4774-afd4-f1639ffd129c",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4c157a2-0fd8-4416-b6ec-811c5a7ff353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_summary</th>\n",
       "      <th>article_url</th>\n",
       "      <th>date_published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Attorney General Merrick B. Garland Statement ...</td>\n",
       "      <td>The Justice Department issued the following st...</td>\n",
       "      <td>https://www.justice.gov//opa/pr/attorney-gener...</td>\n",
       "      <td>2024-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doctor Convicted of $70M Medicare Fraud Scheme</td>\n",
       "      <td>A federal jury convicted a Texas doctor today ...</td>\n",
       "      <td>https://www.justice.gov//opa/pr/doctor-convict...</td>\n",
       "      <td>2024-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Owner of Arkansas Tree Service Business Pleads...</td>\n",
       "      <td>An Arkansas man pleaded guilty to filing a fal...</td>\n",
       "      <td>https://www.justice.gov//opa/pr/owner-arkansas...</td>\n",
       "      <td>2024-05-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       article_title  \\\n",
       "0  Attorney General Merrick B. Garland Statement ...   \n",
       "1     Doctor Convicted of $70M Medicare Fraud Scheme   \n",
       "2  Owner of Arkansas Tree Service Business Pleads...   \n",
       "\n",
       "                                     article_summary  \\\n",
       "0  The Justice Department issued the following st...   \n",
       "1  A federal jury convicted a Texas doctor today ...   \n",
       "2  An Arkansas man pleaded guilty to filing a fal...   \n",
       "\n",
       "                                         article_url date_published  \n",
       "0  https://www.justice.gov//opa/pr/attorney-gener...     2024-05-25  \n",
       "1  https://www.justice.gov//opa/pr/doctor-convict...     2024-05-24  \n",
       "2  https://www.justice.gov//opa/pr/owner-arkansas...     2024-05-24  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_infer = pd.read_csv('data/predicted doj articles.csv')\n",
    "df_infer.drop(columns=['compliance_related'], inplace=True)\n",
    "df_infer.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95eb812d-fa30-4b02-ab4b-8d2f1b035e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_summary</th>\n",
       "      <th>article_url</th>\n",
       "      <th>date_published</th>\n",
       "      <th>cleaned_title_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Attorney General Merrick B. Garland Statement ...</td>\n",
       "      <td>The Justice Department issued the following st...</td>\n",
       "      <td>https://www.justice.gov//opa/pr/attorney-gener...</td>\n",
       "      <td>2024-05-25</td>\n",
       "      <td>attorney general merrick b garland statement e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doctor Convicted of $70M Medicare Fraud Scheme</td>\n",
       "      <td>A federal jury convicted a Texas doctor today ...</td>\n",
       "      <td>https://www.justice.gov//opa/pr/doctor-convict...</td>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>doctor convicted 70m medicare fraud scheme fed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Owner of Arkansas Tree Service Business Pleads...</td>\n",
       "      <td>An Arkansas man pleaded guilty to filing a fal...</td>\n",
       "      <td>https://www.justice.gov//opa/pr/owner-arkansas...</td>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>owner arkansas tree service business pleads gu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       article_title  \\\n",
       "0  Attorney General Merrick B. Garland Statement ...   \n",
       "1     Doctor Convicted of $70M Medicare Fraud Scheme   \n",
       "2  Owner of Arkansas Tree Service Business Pleads...   \n",
       "\n",
       "                                     article_summary  \\\n",
       "0  The Justice Department issued the following st...   \n",
       "1  A federal jury convicted a Texas doctor today ...   \n",
       "2  An Arkansas man pleaded guilty to filing a fal...   \n",
       "\n",
       "                                         article_url date_published  \\\n",
       "0  https://www.justice.gov//opa/pr/attorney-gener...     2024-05-25   \n",
       "1  https://www.justice.gov//opa/pr/doctor-convict...     2024-05-24   \n",
       "2  https://www.justice.gov//opa/pr/owner-arkansas...     2024-05-24   \n",
       "\n",
       "                               cleaned_title_summary  \n",
       "0  attorney general merrick b garland statement e...  \n",
       "1  doctor convicted 70m medicare fraud scheme fed...  \n",
       "2  owner arkansas tree service business pleads gu...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine title and summary\n",
    "df_infer['cleaned_title_summary'] = df_infer['article_title'].astype(str) + \" \" + df_infer['article_summary'].astype(str)\n",
    "\n",
    "# Function call to clean itle and summary text\n",
    "df_infer['cleaned_title_summary'] = df_infer['cleaned_title_summary'].apply(clean_text)\n",
    "\n",
    "df_infer.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26c601fe-4850-48e3-93ec-1b084be875ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set title/summary column to list\n",
    "titles_summaries = df_infer['cleaned_title_summary'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7c1e25b-6f2e-4e86-9283-cc2909309a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast list items to strings\n",
    "texts = [str(summary) for summary in titles_summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e2ee40e-aeac-426c-ab08-4591e51bbfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = 'finetuned_bert_model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a4af78-847f-4031-a596-a3f5fc2a1b80",
   "metadata": {},
   "source": [
    "#### via pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24f69789-6408-4041-9ce7-59b94d106d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classified summaries done.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('sentiment-analysis', model=finetuned_model)\n",
    "classified_texts = classifier(texts)\n",
    "\n",
    "# print(classified_texts[:3)\n",
    "# print()\n",
    "print('classified summaries done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69dcfd4-41dc-4e35-8675-25a094b2c697",
   "metadata": {},
   "source": [
    "#### via pure torch (replicated pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2622ebfa-53f1-421f-ab42-7478598ff1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classifications: 129\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(finetuned_model)\n",
    " \n",
    "# Load pretrained model\n",
    "dilbert_finetuned_model = AutoModelForSequenceClassification.from_pretrained(finetuned_model)\n",
    "\n",
    "# List to hold classifed text label booleans and score probabilties \n",
    "classifications = []\n",
    "\n",
    "# Iterate title/summary texts\n",
    "for text in texts:\n",
    "   \n",
    "    # inputs = tokenizer(text, return_tensors='pt')\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    # print(inputs)\n",
    "    \n",
    "    # with torch.no_grad():\n",
    "    outputs = dilbert_finetuned_model(**inputs)\n",
    "    # print(outputs)\n",
    "\n",
    "    predicted_class_id = outputs.logits.argmax().item()\n",
    "    # print(predicted_class_id)\n",
    "    \n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)[0]\n",
    "    score = np.round(predictions[predicted_class_id].item(), 5)\n",
    "    # print(score)\n",
    "\n",
    "    label = dilbert_finetuned_model.config.id2label[predicted_class_id]\n",
    "    # print(label)\n",
    "    \n",
    "    classification = {'label': label, 'score': score}\n",
    "    classifications.append(classification)\n",
    "\n",
    "print(f'Number of classifications: {len(classifications)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f889da2-4734-43a8-af3a-ca08766bb83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'FALSE', 'score': 0.99806}\n",
      "{'label': 'TRUE', 'score': 0.99928}\n",
      "{'label': 'TRUE', 'score': 0.99924}\n"
     ]
    }
   ],
   "source": [
    "for classfication in classifications[:3]:\n",
    "    print(classfication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be0f06f7-8b0b-4576-a816-b778588dad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(classifications)\n",
    "# type(classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "940ac111-1bf0-41ad-bb1c-01f899d92057",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('data/preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b400501b-f8ef-4213-9e60-b062a683f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_infer.iloc[85]['article_summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a033f9-7ce1-4444-8aa4-a7b2de67509c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fads",
   "language": "python",
   "name": "fads"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
